data_type: text
repo_path: /federated
word_dictionary_path: utils/word_dictionary.pt
save_name: text_debug

# prepare the federated learning model to be adapted
# resumed_model: model_text_Sep.29_15.54.52/model_last.pt.tar.best
### averaging: model_text_Sep.29_15.54.52/model_last.pt.tar.best
### averaging diff: model_text_Oct.15_15.55.39/model_last.pt.tar.best
### median: model_text_Nov.13_02.48.35/model_last.pt.tar.best

# prepare data
recreate_dataset: false
scale_weights: 100

# adaptation params
multi_gpu: false
test_batch_size: 10
lr: 1
momentum: 0
decay: 0
batch_size: 20
alpha: 0.95
temperature: 6
lamb: 5000

only_eval: false
### only_eval is an option to only evaluate the resumed model locally at each participant's local testset
scratch: false
### scratch is an option to train local models from scratch for each participant
freeze_base: false
ewc: false
kd: false
resumed_fisher: data/text_json_fisher.pt
### averaging: text_averaging_fisher
### averaging diff: text_averaging_diff_fisher
### median: text_median_fisher

local_test_perc: 10
### it will cost some minutes to evaluate the model on all global testset, we offer an alternative option `partial_test' to only 
### evaluate on a random partial_test% subset of the whole global testset, which can speed up the test.
# partial_test: 5

# FedLearning params
adaptation_epoch: 100
number_of_total_participants: 80000

# configs for the NLP model
emsize: 200
nhid: 200
nlayers: 2
dropout: 0.2
tied: true
bptt: 64
clip: 0.25
seed: 1